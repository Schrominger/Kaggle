{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML alogorithm\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理要做的事情\n",
    "\n",
    "- 数值属性数据字和文本属性数据分别处理，分为两个pipeline独立处理后在做FeatureUnion\n",
    "- 文本属性要先补缺，再做one-hot encoding 变为数值数据: __sklearn.preprocessing.LableEncoder__   \n",
    "  补缺---> one-hot encoding\n",
    "\n",
    "- 数值数据要补缺处理，解决NaN值问题：__用sklearn.preprocessing.Imputer来做__\n",
    "- 全部变为数值数据后，处理scaling的问题，正规化(异常值不敏感，但取值范围不能限制在一个固定范围)或者minMax（0-1范围，但是异常值敏感！）:__用 StandardScaler__   \n",
    "  imputer---> Scaler \n",
    "- __(上述两个pipeline合并)__\n",
    "- full_pipeline = FeaturUnion(num_pipeline, text_pipline)  \n",
    "- _输出完整的可直接用于训练的输入的数据集。_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    return:values of the DataFrame because sklearn do not deal with DataFrame.\n",
    "    -------------------------\n",
    "    This  is useful for selecting the num and text attributes.\n",
    "    Choose some specific attributes in the DataFrame.\n",
    "    ------------\n",
    "    \"\"\"\n",
    "    def __init__(self, attri_names):\n",
    "        self.attri_names = attri_names\n",
    "        \n",
    "    # do nothing\n",
    "    def fit(self, indataF, y=None):\n",
    "        return self\n",
    "    \n",
    "    # return selected attributes values as arrays\n",
    "    def transform(self, indataF):\n",
    "        X_arrays = indataF[self.attri_names].values\n",
    "        return X_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding age_cat to the dataset\n",
    "# (0-18 19-39 40-59 >60)\n",
    "def ageClss(age):\n",
    "    whois = 0 # ''\n",
    "    if age <= 18:\n",
    "        whois = 1 #'Child'\n",
    "    elif age <= 39:\n",
    "        whois = 2 #'Teenager'\n",
    "    elif age <= 59:\n",
    "        whois = 3 #'MiddleAge'\n",
    "    elif age == 'NaN':\n",
    "        whois = 0# 'NaN'\n",
    "    else:\n",
    "        whois = 5 #'elder'\n",
    "    return whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对dataFrame 进行操作： 输入dataFrame 输出加入新属性的DataFrame\n",
    "#----------------------------------------------------------\n",
    "class CombineAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transform an array into array plus new attributes values from adding two old attributes.\n",
    "    attri_names: the old attributes used for addition.\n",
    "                 you may add more hyperparameters such as the weight of addiotion.\n",
    "    newAttriName: new attributes name\n",
    "    -------------\n",
    "    return: A dataFrame with new attributes.\n",
    "    \"\"\"\n",
    "    def __init__(self, attri_names):\n",
    "        self.attri_names = attri_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        #Xadder = dataSet[self.attri_names[0]].values\n",
    "        #for att in self.attri_names[1:]:\n",
    "        #     Xadder += dataSet[att].values\n",
    "        Xadder = X[:,0] + X[:,1]        \n",
    "        return np.c_[X, Xadder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'Capt': 1, \n",
    "   'Col': 2, \n",
    "   'Don': 1,\n",
    "   'Dr': 7,\n",
    "   'Jonkheer': 1,\n",
    "   'Lady': 1,\n",
    "   'Major': 2,\n",
    "   'Master': 40,\n",
    "         'Miss': 182,\n",
    "         'Mlle': 2,\n",
    "         'Mme': 1,\n",
    "         'Mr': 517,\n",
    "         'Mrs': 125,\n",
    "         'Ms': 1,\n",
    "         'Rev': 6, 牧师\n",
    "         'Sir': 1,\n",
    "         'the Countess': 1})女伯爵\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrebyreSplitStrip(name):\n",
    "    m = re.split(r'\\,|\\.',name)\n",
    "    if m is not None:\n",
    "        prefix = m[1].strip()\n",
    "    else:\n",
    "        # 如果每天title就设为'Mr'\n",
    "        prefix = 'Mr'\n",
    "    # 做一个map 判断把相近的titlemap到一类里去！\n",
    "    MrSet = ('Sir','Mr')\n",
    "    MrsSet = ('Miss','Mrs','Lady', 'Mme' )\n",
    "    MsSet = ('Miss','Mlle', 'Ms' )\n",
    "    eliteSet = ('Don', 'Dr', 'Master') \n",
    "    noble = ('the Countess', 'Major', 'Col')\n",
    "    \n",
    "    if prefix in MrSet:\n",
    "        prefix = 'Mr'\n",
    "    elif prefix in MrsSet:\n",
    "        prefix = 'Mrs'\n",
    "    elif prefix in eliteSet:\n",
    "        prefix = 'elite'\n",
    "    elif prefix in noble:\n",
    "        prefix = 'noble'\n",
    "    else:\n",
    "        prefix = 'others'\n",
    "    \n",
    "    return prefix\n",
    "\n",
    "    \n",
    "def newCabin(cabin):\n",
    "    if cabin is not np.nan:\n",
    "        newcabin = cabin[0]\n",
    "    else:\n",
    "        # 这里应该暂先设置为最大概率的Cabin\n",
    "        newcabin = 'X'\n",
    "    # 单独处理异常值\n",
    "    if newcabin=='T': newcabin = 'X'\n",
    "        \n",
    "    return newcabin\n",
    "# 处理Name属性的匹配问题，提取特征，wholeWord开关：取姓名的title还是取Cabin的首字母\n",
    "class extractWordOfTextAttr(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    提前Name里的title做粗粒化，提取Cabin的首字母\n",
    "    增加新的特征：mother or not, child or not 在数值里面增加用age判断 ?\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, titleOr1Letter=[0,3,4]):\n",
    "        self.titleOr1Letter = titleOr1Letter\n",
    "\n",
    "    def fit(self, X):\n",
    "          return self\n",
    "        \n",
    "    def transform(self, X ,y=None):\n",
    "    # extract title of Name , first letter of Cabin\n",
    "        for ix_ in range(X.shape[0]):\n",
    "            X[ix_, self.titleOr1Letter[0]] = getPrebyreSplitStrip(X[ix_, self.titleOr1Letter[0]])\n",
    "            X[ix_, self.titleOr1Letter[1]] = newCabin(X[ix_, self.titleOr1Letter[1]])\n",
    "            if X[ix_,self.titleOr1Letter[2]] is np.nan:\n",
    "                X[ix_,self.titleOr1Letter[2]] = 'S'\n",
    "        # ---------------------------------------------\n",
    "        # 转换为数字编码，为后续的OneHot做准备\n",
    "        encoder = LabelEncoder()\n",
    "        \n",
    "        X[:,self.titleOr1Letter[0]] = encoder.fit_transform(X[:, self.titleOr1Letter[0]])\n",
    "        X[:,self.titleOr1Letter[1]] = encoder.fit_transform(X[:, self.titleOr1Letter[1]])\n",
    "        # 把embarked也转换为数字\n",
    "        X[:, self.titleOr1Letter[2]] = encoder.fit_transform(X[:, self.titleOr1Letter[2]])\n",
    "        # ---------------------------------------------------\n",
    "        return X\n",
    "    \n",
    "# checked !\n",
    "class Sex2Gender(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    cat_pipeline: transform the second('male','female') col of X to (0,1)\n",
    "    \"\"\"\n",
    "    def __init__(self, col=2):\n",
    "        self.col = col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for ix_ in range(X.shape[0]):\n",
    "            X[ix_, self.col] = int(X[ix_, self.col]=='male')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ START ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet0 = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLabels = dataSet0.copy()['Survived'].values\n",
    "dataSet = dataSet0.copy()\n",
    "dataSet.drop(['Survived','PassengerId', 'Ticket'], axis=1, inplace=True)\n",
    "dataSet['age_cat'] = dataSet['Age'].map(ageClss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "5       3                                   Moran, Mr. James    male   NaN   \n",
       "6       1                            McCarthy, Mr. Timothy J    male  54.0   \n",
       "7       3                     Palsson, Master. Gosta Leonard    male   2.0   \n",
       "8       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0   \n",
       "9       2                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0   \n",
       "\n",
       "   SibSp  Parch     Fare Cabin Embarked  age_cat  \n",
       "0      1      0   7.2500   NaN        S        2  \n",
       "1      1      0  71.2833   C85        C        2  \n",
       "2      0      0   7.9250   NaN        S        2  \n",
       "3      1      0  53.1000  C123        S        2  \n",
       "4      0      0   8.0500   NaN        S        2  \n",
       "5      0      0   8.4583   NaN        Q        5  \n",
       "6      0      0  51.8625   E46        S        3  \n",
       "7      3      1  21.0750   NaN        S        1  \n",
       "8      0      2  11.1333   NaN        S        2  \n",
       "9      1      0  30.0708   NaN        C        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_ATTRI = ['Name', 'Pclass', 'Sex','Cabin', 'Embarked', 'age_cat']\n",
    "NUM_ATTRI = ['SibSp', 'Parch', 'Fare','Age']\n",
    "USELESS_ATTRI = ['Ticket']\n",
    "add_attr = ['SibSp', 'Parch']\n",
    "# 被丢掉一些无用属性\n",
    "drop_attri_names = ['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet0['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet0['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    688\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet0['Cabin'].map(newCabin).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  注意到一个异常值 for Cabin： 'T': 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'A': 15,\n",
       "         'B': 47,\n",
       "         'C': 59,\n",
       "         'D': 33,\n",
       "         'E': 32,\n",
       "         'F': 13,\n",
       "         'G': 4,\n",
       "         'X': 688})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "Counter([newCabin(aa) for aa in dataSet0['Cabin'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Braund, Mr. Owen Harris' 3 'male' nan 'S' 2]\n",
      " ['Cumings, Mrs. John Bradley (Florence Briggs Thayer)' 1 'female' 'C85'\n",
      "  'C' 2]\n",
      " ['Heikkinen, Miss. Laina' 3 'female' nan 'S' 2]\n",
      " ...\n",
      " ['Johnston, Miss. Catherine Helen \"Carrie\"' 3 'female' nan 'S' 5]\n",
      " ['Behr, Mr. Karl Howell' 1 'male' 'C148' 'C' 2]\n",
      " ['Dooley, Mr. Patrick' 3 'male' nan 'Q' 2]]\n",
      "[[0 3 1 7 2 2]\n",
      " [1 1 0 2 0 2]\n",
      " [1 3 0 7 2 2]\n",
      " ...\n",
      " [1 3 0 7 2 5]\n",
      " [0 1 1 2 0 2]\n",
      " [0 3 1 7 1 2]]\n"
     ]
    }
   ],
   "source": [
    "### This cell is used for test every class independently.\n",
    "indataF = dataSet.copy()\n",
    "sel = DataFrameSelector(CAT_ATTRI)\n",
    "CAT = sel.fit_transform(indataF)\n",
    "print(CAT)\n",
    "extract = extractWordOfTextAttr()\n",
    "cat = extract.fit_transform(CAT)\n",
    "sex2g = Sex2Gender()\n",
    "dd = sex2g.transform(cat)\n",
    "print(dd)\n",
    "#oneh = OneHotEncoder()\n",
    "#ee = oneh.fit_transform(dd)\n",
    "#Counter(dd[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Features are:    \n",
    "1.  PassengerId    \n",
    "2.  Survived   \n",
    "3.  Pclass   \n",
    "4.  Name   \n",
    "5.  Sex   \n",
    "6.  Age   \n",
    "7.  SibSp   \n",
    "8.  Parch   \n",
    "9.  Ticket   \n",
    "10.  Fare   \n",
    "11.  Cabin    \n",
    "12.  Embarked   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __这个数值特征的pipeline的流水线操作是： __  \n",
    ">    1.告诉我要提取的列名，从数据集里提取指定的_数值_特征的值   \n",
    ">    2.对所有的数值特征进行补缺操作，用中位数来补缺    \n",
    ">    3.增加属性Relatives,用’孩子配偶‘数加’父母兄弟姐妹‘数，作为一个’亲人‘特征   \n",
    ">    4.对数值数据做标准化处理    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入一个DataFrame, 输出一个数组而非DataFrame\n",
    "num_pipeline = Pipeline([('selector', DataFrameSelector(NUM_ATTRI)),\n",
    "                        ('imputer', Imputer(strategy='median')), \n",
    "                         ('adder', CombineAttributesAdder(add_attr)),\n",
    "                        # (\"poly_feature\", PolynomialFeatures(degree=2)),\n",
    "                        ('std_scaler', StandardScaler()), \n",
    "                        ])\n",
    "#####\n",
    "# num_data = num_pipeline.fit_transform(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __这个pipeline的流水线操作是： __  \n",
    ">    1.告诉我要提取的列名，从数据集里提取指定的类别特征的值   \n",
    ">    2.对指定的列进行特征engineering，这里对Name提取它的Title，对Cabin提取首字母；并都转换为数字标签！   \n",
    ">    3.把性别特征转换为（0，1）   \n",
    ">    4.对现在的类别特征的数据进行OneHot编码，输出编码后的数据   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先补全分类标签如果有缺失的话？或者说缺失当做单独的一类\n",
    "# 输入一个DataFrame, 输出一个数组而非DataFrame\n",
    "cat_pipeline = Pipeline([('selector', DataFrameSelector(CAT_ATTRI)),\n",
    "                         # 提取'Name'里面的title，提取’Cabin‘的首字母；记得完成补全的操作！\n",
    "                         # titleOr1Letter： 告诉transformer，也就是这里的extraWordofTextAttr,对那一列操作以及操作什么\n",
    "                         #               :  [0,3]  意思是对第一列和第四列操作提取字符的变换器\n",
    "                         # -----------------------------------------------------------\n",
    "                         # 提取的步骤里面顺便把类别分好！变成数字编码的类别！！！！\n",
    "                         #-------------------------------------------------------------\n",
    "                         ('extractor', extractWordOfTextAttr(titleOr1Letter=[0,3,4])), \n",
    "                         ('sex2gen', Sex2Gender(col=2)), # 第二列性别变为数字,输入为告诉哪一列是性别\n",
    "                         # 此时所有的类别变量都变为离散的数字类别，做one-hot 编码\n",
    "                         ('one_hot_encode', OneHotEncoder())# OneHot 编码\n",
    "                        ])\n",
    "####\n",
    "#cat_data = cat_pipeline.fit_transform(dataSet).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[(\"num_pipeline\",num_pipeline),\n",
    "                                              (\"cat_pipeline\", cat_pipeline),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43279337, -0.47367361, -0.50244517, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.43279337, -0.47367361,  0.78684529, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.48885426, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.43279337,  2.00893337, -0.17626324, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.04438104, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.49237783, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = full_pipeline.fit_transform(dataSet)\n",
    "Xtrain = full_data.toarray()\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 30)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 测试集，用于提交结果\n",
    "testSet0 = pd.read_csv('test.csv')\n",
    "testSet = testSet0.copy()\n",
    "testSet.drop(['PassengerId', 'Ticket'], axis=1, inplace=True)\n",
    "testSet['age_cat'] = testSet['Age'].map(ageClss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    327\n",
       "C     35\n",
       "B     18\n",
       "D     13\n",
       "E      9\n",
       "F      8\n",
       "A      7\n",
       "G      1\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet0['Cabin'].map(newCabin).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4745452 , -0.47367361, -0.49078316, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.43279337, -0.47367361, -0.50747884, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.45336687, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.4745452 , -0.47367361, -0.50244517, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.48633742, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.43279337,  0.76762988, -0.19824428, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = full_pipeline.transform(testSet).toarray()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 30), (418, 30))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机森林\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=5, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "# lin_svc = LinearSVC(C=1, loss=\"hinge\")\n",
    "# lin_svc.fit(Xtrain, yLabels)\n",
    "\n",
    "# svm_clf = SVC(kernel=\"poly\", degree=5, coef0=1, C=5)  score:0.76\n",
    "#svm_clf = SVC(kernel=\"poly\", degree=5, coef0=1, C=1) # score:0.79425 2018/08/12我的目前最高分\n",
    "svm_clf = SVC(C= 1.0, gamma= 0.05, kernel='rbf')\n",
    "svm_clf.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "y_test_predict = pd.Series(svm_clf.predict(test_data))\n",
    "\n",
    "result = pd.DataFrame({\"PassengerId\":testSet0[\"PassengerId\"].values, 'Survived':y_test_predict})\n",
    "result.to_csv(\"svm_clf_rbf2000.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.01, 0.03, 0.05, 0.08], 'C': [0.5, 1.0, 3.0], 'degree': [1, 3, 5, 6]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearch for the SVM\n",
    "para_grid = [{'kernel':['rbf'], 'gamma':[0.01, 0.03, 0.05, 0.08], 'C':[ 0.5, 1.0, 3.0], 'degree':[1,3,5,6]}]\n",
    "grid_search = GridSearchCV(svm_clf, para_grid, cv=8)\n",
    "\n",
    "grid_search.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/papageno/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'C': 1.0, 'degree': 1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       " 0.8282828282828283,\n",
       " [mean: 0.80359, std: 0.01810, params: {'C': 0.5, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02186, params: {'C': 0.5, 'degree': 1, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02403, params: {'C': 0.5, 'degree': 1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02640, params: {'C': 0.5, 'degree': 1, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.80359, std: 0.01810, params: {'C': 0.5, 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02186, params: {'C': 0.5, 'degree': 3, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02403, params: {'C': 0.5, 'degree': 3, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02640, params: {'C': 0.5, 'degree': 3, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.80359, std: 0.01810, params: {'C': 0.5, 'degree': 5, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02186, params: {'C': 0.5, 'degree': 5, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02403, params: {'C': 0.5, 'degree': 5, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02640, params: {'C': 0.5, 'degree': 5, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.80359, std: 0.01810, params: {'C': 0.5, 'degree': 6, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02186, params: {'C': 0.5, 'degree': 6, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82492, std: 0.02403, params: {'C': 0.5, 'degree': 6, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02640, params: {'C': 0.5, 'degree': 6, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.81930, std: 0.01917, params: {'C': 1.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02109, params: {'C': 1.0, 'degree': 1, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82828, std: 0.02254, params: {'C': 1.0, 'degree': 1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02840, params: {'C': 1.0, 'degree': 1, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.81930, std: 0.01917, params: {'C': 1.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02109, params: {'C': 1.0, 'degree': 3, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82828, std: 0.02254, params: {'C': 1.0, 'degree': 3, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02840, params: {'C': 1.0, 'degree': 3, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.81930, std: 0.01917, params: {'C': 1.0, 'degree': 5, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02109, params: {'C': 1.0, 'degree': 5, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82828, std: 0.02254, params: {'C': 1.0, 'degree': 5, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02840, params: {'C': 1.0, 'degree': 5, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.81930, std: 0.01917, params: {'C': 1.0, 'degree': 6, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02109, params: {'C': 1.0, 'degree': 6, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82828, std: 0.02254, params: {'C': 1.0, 'degree': 6, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.82267, std: 0.02840, params: {'C': 1.0, 'degree': 6, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.01846, params: {'C': 3.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82604, std: 0.02296, params: {'C': 3.0, 'degree': 1, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02774, params: {'C': 3.0, 'degree': 1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.81706, std: 0.02621, params: {'C': 3.0, 'degree': 1, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.01846, params: {'C': 3.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82604, std: 0.02296, params: {'C': 3.0, 'degree': 3, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02774, params: {'C': 3.0, 'degree': 3, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.81706, std: 0.02621, params: {'C': 3.0, 'degree': 3, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.01846, params: {'C': 3.0, 'degree': 5, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82604, std: 0.02296, params: {'C': 3.0, 'degree': 5, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02774, params: {'C': 3.0, 'degree': 5, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.81706, std: 0.02621, params: {'C': 3.0, 'degree': 5, 'gamma': 0.08, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.01846, params: {'C': 3.0, 'degree': 6, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  mean: 0.82604, std: 0.02296, params: {'C': 3.0, 'degree': 6, 'gamma': 0.03, 'kernel': 'rbf'},\n",
       "  mean: 0.82716, std: 0.02774, params: {'C': 3.0, 'degree': 6, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  mean: 0.81706, std: 0.02621, params: {'C': 3.0, 'degree': 6, 'gamma': 0.08, 'kernel': 'rbf'}])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_, grid_search.best_score_,grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emsemble Learning:\n",
    "\n",
    "#### a simply try !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/papageno/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomF...='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble Learning \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(kernel=\"poly\", degree=5, coef0=1, C=1)\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr',log_clf),('rf', rnd_clf),('svc', svm_clf),('sgd',sgd_clf)], voting='hard')\n",
    "\n",
    "voting_clf.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/papageno/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "y_test_predict = pd.Series(voting_clf.predict(test_data))\n",
    "\n",
    "result = pd.DataFrame({\"PassengerId\":testSet0[\"PassengerId\"].values, 'Survived':y_test_predict})\n",
    "result.to_csv(\"emsemble_svm_rnd_log.csv\",index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.5, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# 0.78947\n",
    "# bag_clf = BaggingClassifier(RandomForestClassifier(), n_estimators=900, max_samples=0.5, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "# 0.78468\n",
    "bag_clf = BaggingClassifier(RandomForestClassifier(), n_estimators=500, max_samples=0.5, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "bag_clf.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "y_test_predict = pd.Series(bag_clf.predict(test_data))\n",
    "\n",
    "result = pd.DataFrame({\"PassengerId\":testSet0[\"PassengerId\"].values, 'Survived':y_test_predict})\n",
    "result.to_csv(\"Forest_bagging_sample0.5_500esitimators.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_spl..._estimators=10, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [500, 1000], 'max_samples': [0.5, 0.7, 0.8, 0.9]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearch for the bagging\n",
    "bag_clf1 = BaggingClassifier(RandomForestClassifier(), bootstrap=True, n_jobs=-1)\n",
    "para_grid = [{'n_estimators':[500, 1000], 'max_samples':[0.5, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(bag_clf1, para_grid)\n",
    "\n",
    "grid_search.fit(Xtrain, yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/papageno/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_samples': 0.7, 'n_estimators': 1000},\n",
       " 0.8237934904601572,\n",
       " [mean: 0.82267, std: 0.01657, params: {'max_samples': 0.5, 'n_estimators': 500},\n",
       "  mean: 0.82043, std: 0.01931, params: {'max_samples': 0.5, 'n_estimators': 1000},\n",
       "  mean: 0.82155, std: 0.02250, params: {'max_samples': 0.7, 'n_estimators': 500},\n",
       "  mean: 0.82379, std: 0.02063, params: {'max_samples': 0.7, 'n_estimators': 1000},\n",
       "  mean: 0.82379, std: 0.02063, params: {'max_samples': 0.8, 'n_estimators': 500},\n",
       "  mean: 0.82379, std: 0.02222, params: {'max_samples': 0.8, 'n_estimators': 1000},\n",
       "  mean: 0.82155, std: 0.01803, params: {'max_samples': 0.9, 'n_estimators': 500},\n",
       "  mean: 0.82155, std: 0.02076, params: {'max_samples': 0.9, 'n_estimators': 1000}])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_, grid_search.best_score_, grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorFlow: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
