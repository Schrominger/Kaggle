{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal   \n",
    "It is your job to predict if a passenger survived the sinking of the Titanic or not. \n",
    "For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.\n",
    "\n",
    "### Metric\n",
    "Your score is the percentage of passengers you correctly predict. This is known simply as \"accuracy”.\n",
    "\n",
    "### Submission File Format\n",
    "You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "\n",
    "PassengerId (sorted in any order)\n",
    "Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n",
    "PassengerId,Survived\n",
    " 892,0\n",
    " 893,1\n",
    " 894,0\n",
    " Etc.\n",
    "You can download an example submission file (gender_submission.csv) on the [Data page](https://www.kaggle.com/c/titanic/data).   \n",
    "\n",
    "**Variable Notes**    \n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5   \n",
    "\n",
    "sibsp: The dataset defines family relations in this way...   \n",
    "Sibling = brother, sister, stepbrother, stepsister   \n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)   \n",
    "\n",
    "parch: The dataset defines family relations in this way...   \n",
    "Parent = mother, father   \n",
    "Child = daughter, son, stepdaughter, stepson   \n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___Memos for M.Xue___\n",
    "This is an excersice in **Chapter2** of [\"Hands-On Machine Learning with Scikit-Learn and TensorFlow\",A. Geron](https://item.jd.com/12241590.html)\n",
    "\n",
    "- Getting a first feeling and touch of building a Machine Learning system.\n",
    "- Working with the book's stream step by step.\n",
    "- Picking up the skills of using pipelines on the data transformations.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main steps\n",
    " 1. Frame the problem and look at the big picture.\n",
    " 2. Get the data.\n",
    " 3. Discover and visualize the data to gain insights.\n",
    " 4. Prepare the data for Machine Learning algorithms.\n",
    " 5. Select a model and train it.\n",
    " 6. Fine-tune your model.\n",
    " 7. Present your solution.\n",
    " 8. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ming/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichFeatures(df):\n",
    "    count = 0\n",
    "    print('The Features are: ')\n",
    "    for feature in df.columns:\n",
    "        count = count + 1\n",
    "        print('%d. '%(count), feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for test\n",
    "def split_train_test(data_set,test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    split the dataset into train_set and test_set by the test_ratio\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data_set))\n",
    "    test_set_size = int(test_ratio*len(data_set))\n",
    "    test_indices,train_indices = shuffled_indices[:test_set_size],shuffled_indices[test_set_size:]\n",
    "    \n",
    "    return data_set.iloc[train_indices],data_set.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Features are: \n",
      "1.  PassengerId\n",
      "2.  Survived\n",
      "3.  Pclass\n",
      "4.  Name\n",
      "5.  Sex\n",
      "6.  Age\n",
      "7.  SibSp\n",
      "8.  Parch\n",
      "9.  Ticket\n",
      "10.  Fare\n",
      "11.  Cabin\n",
      "12.  Embarked\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_set, test_set = train_test_split(data_set, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(len(train_set),\" train + \", len(test_set), \"test\")\n",
    "\n",
    "# know what features are in the data:\n",
    "whichFeatures(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Frame the problem and look at the Big Picture__ \n",
    "- This a __binary classification__ problem.\n",
    "- If one _randomly_ guess 0 or 1 of the survival for the passengers, he could be still get an accurracy of 50%.   \n",
    "- 考虑到年龄和性别对生存概率的影响极大，应该按照年龄和性别对数据集进行StratifiedShuffleSplit().   \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showValue_Counts(dataF,cols):\n",
    "    for col in cols:\n",
    "        if dataF.columns.contains(col):\n",
    "            print('-----------')\n",
    "            print(dataF[col].value_counts())\n",
    "            print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "-----------\n",
      "-----------\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "-----------\n",
      "-----------\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "-----------\n",
      "-----------\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n",
      "-----------\n",
      "-----------\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n",
      "-----------\n",
      "-----------\n",
      "B96 B98            4\n",
      "G6                 4\n",
      "C23 C25 C27        4\n",
      "C22 C26            3\n",
      "F2                 3\n",
      "D                  3\n",
      "E101               3\n",
      "F33                3\n",
      "D20                2\n",
      "B77                2\n",
      "B49                2\n",
      "C124               2\n",
      "B58 B60            2\n",
      "E121               2\n",
      "B57 B59 B63 B66    2\n",
      "E33                2\n",
      "B28                2\n",
      "B5                 2\n",
      "C125               2\n",
      "C78                2\n",
      "E8                 2\n",
      "C93                2\n",
      "D17                2\n",
      "B20                2\n",
      "E44                2\n",
      "C92                2\n",
      "C68                2\n",
      "C52                2\n",
      "B18                2\n",
      "E67                2\n",
      "                  ..\n",
      "E34                1\n",
      "A23                1\n",
      "D15                1\n",
      "B78                1\n",
      "C110               1\n",
      "E49                1\n",
      "A24                1\n",
      "E31                1\n",
      "C86                1\n",
      "A6                 1\n",
      "A5                 1\n",
      "A20                1\n",
      "B4                 1\n",
      "F G63              1\n",
      "A16                1\n",
      "B69                1\n",
      "D56                1\n",
      "E17                1\n",
      "B30                1\n",
      "D47                1\n",
      "C30                1\n",
      "E10                1\n",
      "C106               1\n",
      "B38                1\n",
      "C7                 1\n",
      "C32                1\n",
      "B37                1\n",
      "C91                1\n",
      "C90                1\n",
      "E38                1\n",
      "Name: Cabin, Length: 147, dtype: int64\n",
      "-----------\n",
      "-----------\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "cols = ['Survived','Pclass', 'Sex','SibSp','Parch','Cabin','Embarked']\n",
    "showValue_Counts(data_set,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Parch          0.081629\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Pclass        -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = data_set.corr()\n",
    "corr_matrix['Survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据：清洗、重组、提取有用信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面要做的事情：   \n",
    "1. drop不想要的feature.   \n",
    "2. Handling text feature.   \n",
    "3. fill the NAN with certain values\n",
    "4. \"Fare\" 进行一些scale\n",
    "\n",
    "> 先对整个数据集的拷贝做以下操作之后，再去分解为训练集和测试集：   \n",
    "  - （male， female）-> (1,0) : 用gender值代替Sex, 删除Sex \n",
    "  - 'Embarked' -> one hot encoding\n",
    "  - 'Name' -> Prefix, 再粗粒化一下, one-hot 编码\n",
    "  - 'Cabin'值strip()后提取首字母作为客舱的标记\n",
    "  - 删除'Ticket','PassengerId','Cabin' 这些没有信息量的feature\n",
    "  - 考虑如何填充 NAN为合适的值\n",
    "  - __全部数值化或者one-hot 编码处理为full_set__   \n",
    "  \n",
    "   __接下来对数据集按照age_cat分层分割为训练集和测试集，记得删除age_cat，再训练不同模型__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从Name里提取表示头衔的Prefix\n",
    "\n",
    "# 用+表示至少一个字符, .匹配一个任意字符  \\s匹配一个空格\n",
    "def getPrefix(name):\n",
    "    m = re.match(r'([a-zA-Z\\_\\-\\'\\s+]+)(\\,\\s+)([0-9a-zA-Z\\_]+)(\\.)(.+)', name)\n",
    "    if m is not None:\n",
    "        prefix = m.group(3)\n",
    "    else:\n",
    "        prefix='NAN'\n",
    "    return prefix\n",
    "# 上述正则表达式匹配效果并不完美且比较复杂，而且特殊符号要手动考虑进去\n",
    "\n",
    "# 运用re的split 方法来做试试：\n",
    "def getPrebyreSplitStrip(name):\n",
    "    m = re.split(r'\\,|\\.',name)\n",
    "    if m is not None:\n",
    "        prefix = m[1].strip()\n",
    "    else:\n",
    "        prefix='NAN'\n",
    "    return prefix\n",
    "\n",
    "# drop the added feature \"age_cat\"\n",
    "def drop_features(dataF,features):\n",
    "    \"\"\"\n",
    "    features contains the list of features u want to drop!\n",
    "    \"\"\"\n",
    "    for col in features:\n",
    "        if dataF.columns.contains(col):\n",
    "            dataF.drop([col],axis=1,inplace=True)\n",
    "    return dataF\n",
    "\n",
    "# name----> Prefix, drop 'Name'\n",
    "def dataFrame_name2Prefix(df):\n",
    "    if df.columns.contains('Name'):\n",
    "        df['Prefix'] = df['Name'].map(getPrebyreSplitStrip)\n",
    "        df.drop(['Name'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def newCabin(cabin):\n",
    "    if cabin is not np.nan:\n",
    "        newcabin = cabin[0]\n",
    "    else:\n",
    "        newcabin = 'X'\n",
    "    return newcabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepDataSet(dataSet):\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    # add prefix\n",
    "    data_set_pre = dataFrame_name2Prefix(dataSet)\n",
    "    # gender <- sex,  newCabin <- Cabin\n",
    "    data_set_pre['Gender'] = 1*(data_set_pre['Sex']=='male')\n",
    "    data_set_pre['newCabin'] = data_set_pre['Cabin'].apply(newCabin)\n",
    "    \n",
    "    data_set_pre['Relatives'] = data_set_pre['Parch']+data_set_pre['SibSp']\n",
    "    \n",
    "    # fill nan of Age\n",
    "    age_median = data_set_pre['Age'].median()\n",
    "    data_set_pre['Age'].fillna(age_median,inplace=True)\n",
    "    # fill nan of Embarked\n",
    "    data_set_pre['Embarked'].fillna('U',inplace=True)# unkown\n",
    "    \n",
    "    # on-hot encoding \n",
    "    encoder = LabelEncoder()\n",
    "    data_Embarked_encoded = encoder.fit_transform(data_set_pre[\"Embarked\"])\n",
    "    data_set_pre[\"num_Embarked\"] = pd.Series(data_Embarked_encoded)\n",
    "    \n",
    "    data_prefix_encoded = encoder.fit_transform(data_set_pre[\"Prefix\"])\n",
    "    data_set_pre[\"num_prefix\"] = pd.Series(data_prefix_encoded)\n",
    "    \n",
    "    data_newCabin_encoded = encoder.fit_transform(data_set_pre[\"newCabin\"])\n",
    "    data_set_pre[\"num_newCabin\"] = pd.Series(data_newCabin_encoded)\n",
    "    # feature scaling\n",
    "    data_set_pre[\"Fare\"] = data_set_pre[\"Fare\"]*0.1\n",
    "    # drop useless features\n",
    "    drop_features(data_set_pre,['Sex','Ticket','PassengerId','Cabin',\"Embarked\",'Prefix','newCabin']);\n",
    "    return data_set_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_prep = prepDataSet(data_set.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>num_Embarked</th>\n",
       "      <th>num_prefix</th>\n",
       "      <th>num_newCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.12833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.31000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.18625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.10750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.11333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00708</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Gender  Relatives  \\\n",
       "0         0       3  22.0      1      0  0.72500       1          1   \n",
       "1         1       1  38.0      1      0  7.12833       0          1   \n",
       "2         1       3  26.0      0      0  0.79250       0          0   \n",
       "3         1       1  35.0      1      0  5.31000       0          1   \n",
       "4         0       3  35.0      0      0  0.80500       1          0   \n",
       "5         0       3  28.0      0      0  0.84583       1          0   \n",
       "6         0       1  54.0      0      0  5.18625       1          0   \n",
       "7         0       3   2.0      3      1  2.10750       1          4   \n",
       "8         1       3  27.0      0      2  1.11333       0          2   \n",
       "9         1       2  14.0      1      0  3.00708       0          1   \n",
       "\n",
       "   num_Embarked  num_prefix  num_newCabin  \n",
       "0             2          11             8  \n",
       "1             0          12             2  \n",
       "2             2           8             8  \n",
       "3             2          12             2  \n",
       "4             2          11             8  \n",
       "5             1          11             8  \n",
       "6             2          11             4  \n",
       "7             2           7             8  \n",
       "8             2          12             8  \n",
       "9             0          12             8  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_prep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>num_Embarked</th>\n",
       "      <th>num_prefix</th>\n",
       "      <th>num_newCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.064910</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>-0.163517</td>\n",
       "      <td>-0.193635</td>\n",
       "      <td>-0.301116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.157112</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>0.746616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.064910</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.233296</td>\n",
       "      <td>-0.172482</td>\n",
       "      <td>0.096688</td>\n",
       "      <td>0.081163</td>\n",
       "      <td>-0.245619</td>\n",
       "      <td>-0.014205</td>\n",
       "      <td>0.284653</td>\n",
       "      <td>-0.255783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.233296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>-0.200046</td>\n",
       "      <td>0.041540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.172482</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>-0.126422</td>\n",
       "      <td>-0.032548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096688</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.221226</td>\n",
       "      <td>-0.077461</td>\n",
       "      <td>-0.523013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.081163</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>0.104057</td>\n",
       "      <td>0.250075</td>\n",
       "      <td>0.123076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relatives</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>-0.245619</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064701</td>\n",
       "      <td>-0.199883</td>\n",
       "      <td>0.012131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_Embarked</th>\n",
       "      <td>-0.163517</td>\n",
       "      <td>0.157112</td>\n",
       "      <td>-0.014205</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>-0.221226</td>\n",
       "      <td>0.104057</td>\n",
       "      <td>0.064701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071998</td>\n",
       "      <td>0.187015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_prefix</th>\n",
       "      <td>-0.193635</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>0.284653</td>\n",
       "      <td>-0.200046</td>\n",
       "      <td>-0.126422</td>\n",
       "      <td>-0.077461</td>\n",
       "      <td>0.250075</td>\n",
       "      <td>-0.199883</td>\n",
       "      <td>0.071998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_newCabin</th>\n",
       "      <td>-0.301116</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>-0.255783</td>\n",
       "      <td>0.041540</td>\n",
       "      <td>-0.032548</td>\n",
       "      <td>-0.523013</td>\n",
       "      <td>0.123076</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>0.187015</td>\n",
       "      <td>0.043907</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Survived    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "Survived      1.000000 -0.338481 -0.064910 -0.035322  0.081629  0.257307   \n",
       "Pclass       -0.338481  1.000000 -0.339898  0.083081  0.018443 -0.549500   \n",
       "Age          -0.064910 -0.339898  1.000000 -0.233296 -0.172482  0.096688   \n",
       "SibSp        -0.035322  0.083081 -0.233296  1.000000  0.414838  0.159651   \n",
       "Parch         0.081629  0.018443 -0.172482  0.414838  1.000000  0.216225   \n",
       "Fare          0.257307 -0.549500  0.096688  0.159651  0.216225  1.000000   \n",
       "Gender       -0.543351  0.131900  0.081163 -0.114631 -0.245489 -0.182333   \n",
       "Relatives     0.016639  0.065997 -0.245619  0.890712  0.783111  0.217138   \n",
       "num_Embarked -0.163517  0.157112 -0.014205  0.066654  0.038322 -0.221226   \n",
       "num_prefix   -0.193635  0.029099  0.284653 -0.200046 -0.126422 -0.077461   \n",
       "num_newCabin -0.301116  0.746616 -0.255783  0.041540 -0.032548 -0.523013   \n",
       "\n",
       "                Gender  Relatives  num_Embarked  num_prefix  num_newCabin  \n",
       "Survived     -0.543351   0.016639     -0.163517   -0.193635     -0.301116  \n",
       "Pclass        0.131900   0.065997      0.157112    0.029099      0.746616  \n",
       "Age           0.081163  -0.245619     -0.014205    0.284653     -0.255783  \n",
       "SibSp        -0.114631   0.890712      0.066654   -0.200046      0.041540  \n",
       "Parch        -0.245489   0.783111      0.038322   -0.126422     -0.032548  \n",
       "Fare         -0.182333   0.217138     -0.221226   -0.077461     -0.523013  \n",
       "Gender        1.000000  -0.200988      0.104057    0.250075      0.123076  \n",
       "Relatives    -0.200988   1.000000      0.064701   -0.199883      0.012131  \n",
       "num_Embarked  0.104057   0.064701      1.000000    0.071998      0.187015  \n",
       "num_prefix    0.250075  -0.199883      0.071998    1.000000      0.043907  \n",
       "num_newCabin  0.123076   0.012131      0.187015    0.043907      1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_prep.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_set_with_pre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2dc9dc0a5226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowValue_Counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set_with_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_set_with_pre' is not defined"
     ]
    }
   ],
   "source": [
    "showValue_Counts(data_set_with_pre, ['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割数据集为训练集和测试集：stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ed5a8c048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ed5b989b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Knowing the fact that women and chidren go first !\n",
    "# The very importance of features \"Age\" and \"Sex\", \n",
    "# the test set from the whole data set should be representative of the whole set.\n",
    "data_set[\"Age\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[\"Sex\"].value_counts()/len(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding age_class to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding age_cat to the dataset\n",
    "# (0-18 19-39 40-59 >60)\n",
    "def ageClss(age):\n",
    "    whois = ''\n",
    "    if age <= 18:\n",
    "        whois = 'Child'\n",
    "    elif age <= 39:\n",
    "        whois = 'Teenager'\n",
    "    elif age <= 59:\n",
    "        whois = 'MiddleAge'\n",
    "    elif age == 'NaN':\n",
    "        whois = 'NaN'\n",
    "    else:\n",
    "        whois = 'elder'\n",
    "    return whois\n",
    "        \n",
    "data_set['age_cat'] = data_set['Age'].map(ageClss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不需要执行此段\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(data_set,data_set['age_cat']):\n",
    "    strat_train_set = data_set.loc[train_index]\n",
    "    strat_test_set = data_set.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __这里有个问题： 如何实习两个feature的stratified 数据集分割？ 比如这里能否同时兼顾年龄和性别的概率分布？__\n",
    "\n",
    "我的做法：\n",
    " 0. 先把性别特征数值化为0,1    \n",
    " 1. 先把数据集分成男女两部分，再每部分按照feature:age_cat 分层抽样\n",
    " 2. 再合并抽出来的 训练集=男训练集+女训练集 测试集=男训练集+女测试集\n",
    " 3. 要测试只用年龄段和用性别加年龄段做分层抽样的对比效果！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the full data set into male and female\n",
    "male_data_set = data_set[data_set[\"Sex\"]=='male']\n",
    "female_data_set = data_set[data_set[\"Sex\"]=='female']\n",
    "\n",
    "# split the male set and female set according the stratified feature \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratify_split(dataSet,col):\n",
    "    \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    \n",
    "    for train_index, test_index in split.split(dataSet,dataSet[col]):\n",
    "        strat_train_set = data_set.loc[train_index]\n",
    "        strat_test_set = data_set.loc[test_index]\n",
    "    return strat_train_set, strat_test_set\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# stratify the male and female set by the age_cat respectively.\n",
    "strat_male_train_set, strat_male_test_set  = stratify_split(male_data_set,col='age_cat')\n",
    "strat_female_train_set, strat_female_test_set  = stratify_split(female_data_set,col='age_cat')\n",
    "\n",
    "# join the train , test\n",
    "strat_train_set = strat_male_train_set.append(strat_female_train_set)\n",
    "strat_test_set = strat_male_test_set.append(strat_female_test_set)\n",
    "\n",
    "# Till now, we finish the stratified spliting of the full data set first by the gender and then by age_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ======================  Check the stratified split results   =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Sex'].value_counts()/len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set['Sex'].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set['Sex'].value_counts()/len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['age_cat'].value_counts()/len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stratified counts of the age_cat when gender == male\n",
    "data_set[data_set['Sex']=='male']['age_cat'].value_counts()/len(data_set[data_set['Sex']=='male']['age_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stratified counts of the age_cat when gender == FEmale\n",
    "data_set[data_set['Sex']=='female']['age_cat'].value_counts()/len(data_set[data_set['Sex']=='female']['age_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[strat_test_set['Sex']=='male']['age_cat'].value_counts()/len(strat_test_set[strat_test_set['Sex']=='male']['age_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set[strat_train_set['Sex']=='male']['age_cat'].value_counts()/len(strat_train_set[strat_train_set['Sex']=='male']['age_cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 对于Age和age_cat这两个feature，这里有两种做法： __（暂时先用第二种）__   \n",
    " \n",
    "   1. 就是可以把Age这个feature删除，直接用 age_cat 来代替，做后续的训练模型用\n",
    "   2. 只用age_cat 做分割数据集的参考，还是用Age特征来训练模型\n",
    "   3. 都保留，但是这样这两个特征关联度会很高！age_cat 是Age的一个粗粒化表示。\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按年龄、性别比例分好的数据\n",
    "trainSet_with_label = strat_train_set.iloc[:,:].copy()\n",
    "testSet_with_label = strat_test_set.iloc[:,:].copy()\n",
    "\n",
    "Ytrain = trainSet_with_label['Survived']\n",
    "Xtrain = drop_features(trainSet_with_label,['PassengerId','Survived','Cabin','Ticket','age_cat'])\n",
    "\n",
    "Ytest = testSet_with_label['Survived']\n",
    "Xtest = drop_features(testSet_with_label,['PassengerId','Survived','Cabin','Ticket','age_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__头衔匹配有个问题：__   \n",
    "    就是有点头衔出现次数比较少，可能训练集里没有，分割出来的测试集里才有，比如 Dr., Don, Rev,Mlle,Mme.... 这些奇怪的头衔\n",
    "    - Don:  大学教师，（牛津、剑桥大学的）导师，特别研究员;\n",
    "    - Mme: Mademoiselle的缩写 指小姐;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain0, Xtest0 = dataFrame_name2Prefix(Xtrain), dataFrame_name2Prefix(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain0['Prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest0['Prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于 feature 特征的观察  \n",
    "- __Cabin客舱信息内容缺失多，似乎没看到什么关联信息__    \n",
    "- __Ticket 也一下子看不出什么信息__\n",
    "- __PassengerId没有信息量__\n",
    "- 要把prefix 分成少一点的几类，现在的直接提取prefix分类过多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面的任务是需要将字符的转成数值的feature，显示关联度，并尝试训练（2018.08.08）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain insights from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summaries of the Pearson's coeffiecient r:   \n",
    "- ID is irrevalant as in first thinking !\n",
    "\n",
    "- r(Survive,Pclass)=-0.338,r(Survive,Fare)=0.257, r(Pclass,Fare)=-0.55,r(Pclass,Age)=-0.37:   \n",
    "  People with higher socio-economic status (SES) survive more.     \n",
    "- Pclass and the Fare can be merge to one feature in a very crude(r=-0.55 not very close to -1) approximation.\n",
    "\n",
    "- people who with more siblings on board tend to have parents or childeren on the board (r=0.41438).   \n",
    "  maybe we can merge these two by adding them to be \"relatives\".   \n",
    "- (Pclass,Age) r = -0.369226; (Fare,Pclass) r = -0.55\n",
    "\n",
    "- (Age,sibling) r = -0.30825 : reasonable!   \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training data...\n",
    "\n",
    "- Transform the gender (female,male) $\\rightarrow$ (0,1). Gender should be a important featur in deciding the survival probability.   \n",
    "- Merge features \"Relatives\"=\"SibSp\"+\"Parch\".\n",
    "- Drop \"Cabin\", \"Name\" and \"Ticket\" in the training features, because they are irrevelant.   \n",
    "- Embarked->[0,1,2,3..] or using one-hot encoding ?\n",
    "- y_train = data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "data_input = pd.read_csv('train.csv')\n",
    "data_work = data_input.copy()\n",
    "y_traing_labels = data_work[\"Survived\"]\n",
    "# ---------------------------------------------------------\n",
    "# Try to transform all the feature value to numeric values.\n",
    "# ----------------------------------------------------------\n",
    "def prepareData(data_work):\n",
    "# engeering new feature: \"Relatives\"\n",
    "    data_work[\"Relatives\"] = data_work[\"SibSp\"]+data_work[\"Parch\"]\n",
    "\n",
    "# (female,male)->(0,1)\n",
    "    encoder = LabelEncoder()\n",
    "    data_sex_encoded = encoder.fit_transform(data_work[\"Sex\"])\n",
    "    data_work[\"Gender\"] = pd.Series(data_sex_encoded)\n",
    "\n",
    "#data_work[\"Embarked\"].fillna(\"X\")\n",
    "    data_Embarked_encoded = encoder.fit_transform(data_work[\"Embarked\"].fillna('X'))\n",
    "    data_work[\"num_Embarked\"] = pd.Series(data_Embarked_encoded)\n",
    "    \n",
    "# drop irrevalent features\n",
    "    drop_attributes = [\"Name\",\"Ticket\",\"Cabin\",\"SibSp\",\"Parch\",\"Sex\",\"Embarked\"]\n",
    "    data_work.drop(drop_attributes,axis=1,inplace=True)\n",
    "\n",
    "# if age=na, fill it with the median of age. \n",
    "    age_median = data_work[\"Age\"].median()\n",
    "    data_work[\"Age\"].fillna(age_median,inplace=True)\n",
    "    \n",
    "    #imputer = Imputer(strategy=\"median\")\n",
    "    #imputer.fit(data_work)\n",
    "    return data_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_attributes = list(data_work.columns)\n",
    "attributes = ['Pclass','Age', 'Fare','Relatives', 'Gender', 'num_Embarked']\n",
    "scatter_matrix(data_work[attributes],figsize=(18,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_work.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ming/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=16,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data_work_pre=  data_set_prep.copy()#prepareData(data_work)\n",
    "y_traing_labels = data_work_pre['Survived']\n",
    "data_work_pre.drop(\"Survived\",axis=1,inplace=True)\n",
    "#lin_reg = LinearRegression()\n",
    "#lin_reg.fit(data_work,y_traing_labels)\n",
    "\n",
    "tree_clf=DecisionTreeClassifier()\n",
    "tree_clf.fit(data_work_pre,y_traing_labels)\n",
    "\n",
    "sgd_clf=SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(data_work_pre,y_traing_labels)\n",
    "\n",
    "rnd_clf=RandomForestClassifier(n_estimators=500,max_leaf_nodes=16,n_jobs=-1)\n",
    "rnd_clf.fit(data_work_pre,y_traing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.csv')\n",
    "data_test_pre = prepDataSet(data_test.copy())\n",
    "#data_set_prep = prepDataSet(data_set.copy())\n",
    "y_test = pd.Series(rnd_clf.predict(data_test_pre.fillna(28.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"PassengerId\":data_test[\"PassengerId\"].values, 'Survived':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result4_rnd.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traing_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
